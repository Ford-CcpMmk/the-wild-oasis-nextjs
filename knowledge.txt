REACT SERVER COMPONENT (RSC)

React Server Components is a completely new full-stack architecture for building React apps. It introduces the server as a first class citizen in React apps, which means that the server is now an integral part of the React component trees of our applications. Or in other words, the Reactory now extends all the way to the server, like a bridge that closes the gap between client and server. And the way in which React does that is by introducing a new kind of component which are server components.

The term React Server Components, which you'll often see abbreviated as RSC, is the name of this whole new paradigm, so, this new architecture. The term "server component" alone is then the name of the new type of component that RSC introduces. And these are components that are only rendered on the server, never on the client.

They're usually responsible for fetching data right on the server. Now, since server components run only on the server, they have no interactivity, so no state, which means that they require exactly zero JavaScript in the downloadable bundle to do their job. So if we think about this, with server components, we can essentially build our application's backend also with React, which is pretty amazing.

Now, besides server components, of course we still have our old regular components that we already know and that run entirely on the client. Therefore these are called client components and they are responsible for the interactivity.

So together, client and server components allow us to write frontend code, right next to backend code in a way that feels completely natural because it feels just like the regular React apps that we've been building so far, we're still using just components and can even compose server and client components together to build full-stack apps that are really entirely controlled by React.

Now here is one very important thing to understand about all this. React Server Components are not active by default in new React apps. And this makes sense because there is no server involved in a Vite application. So the server needs to be somewhere, it needs to be integrated into this whole idea. And so that's where full-stack frameworks like Next.js or Remix finally come into the picture again.
So basically, React provides this architecture and frameworks can then choose to adopt and to implement it if they want. And that's exactly what Next.js did in the app router. So any app that we built in the Next.js app folder will use this new RSC architecture in which server components become the default components actually.

So again, server components are now the new default components in this new model. Client components then basically become opt in, so we need to specifically tell a component that it should be a client component if that's what we need.


SUSPENSE

Suspense is a built-in React component that we can use to catch or to isolate components that are not ready to be rendered yet because they're doing some asynchronous work. And we say that these components or even entire sub trees are suspending. So conceptually, we can think of Suspense as being like a catch block in a try-catch statement. But instead of catching errors, it catches components that are suspending.

Now the important question here is what might actually cause a component to be suspending in the first place?

There are two main reasons, which are both asynchronous tasks.

1. fetching data using a library that supports Suspense.
2. loading additional code using React's lazy loading feature.

Now the main use case of Suspense is indeed data fetching. Just note how I mentioned that we need to use a data fetching library that actually supports Suspense. For example, React Query, Remix or also Next.js,


STATIC VS. DYNAMIC RENDERING

STATIC RENDERING
- the HTML for the route is generated at build time, which means that the markup is rendered whenever we run the "build" command in our Next.js app. So it's basically the developer who triggers the rendering. What matters is that static essentially means rendered just once at build time. And this is useful whenever the data for the route in question doesn't change very often, and most importantly, is not personalized to the user. So in the previous slide, we had a product page as a static page, which doesn't need any data that belongs to or is generated by the user.

Now, there's also a special flavor of static rendering, which is called incremental static regeneration, which is just the fancy way of saying that a route can be re-rendered periodically in the background.


DYNAMIC RENDERING
- the HTML is generated at request time. Or in other words, the server renders a new version of the page for each request that hits the server. So in this strategy, it's actually the user who triggers the rendering. And this makes sense if the data changes constantly and is personalized to the user. And back to our e-commerce example, a shopping cart might be a good candidate for dynamic rendering because each user will have a different shopping cart.

Dynamic rendering is also necessary whenever rendering the route requires information that depends on the request itself. For example, the search params from the URL or a cookie or something like a header.


BY DEFAULT

Now by default in Next.js, all routes are rendered statically, even when the page component or another component in the tree fetches some data. It's only under certain conditions that Next.js will actually switch a route to dynamic rendering.

And the idea behind this is that static pages are way faster. First, because they have already been pre-generated and don't need to be rebuilt for every request, which saves time and resources. And second, because static assets like this can very easily be hosted on a so-called CDN, which means content delivery network. And this is what happens automatically for each route when we deploy our Next.js app to Vercel, which is the company that built the Next.js framework.

On the other hand, each dynamic route when deployed to Vercel will automatically become a serverless function.

Finally, I just want to mention that in certain situations like when we have no personalized user data at all, all routes in the app might actually be static. In this case, the entire app can be exported as a static site in a process that we call static site generation or SSG for short.


WHEN NEXT.JS SWITCH A ROUTE FROM STATIC TO DYNAMIC? 

Saying this already implies that it's usually not us developers who directly choose whether a route should be statically or dynamially rendered. Instead, there are a few scenarios in which Next.js will automatically decide to switch from the default to dynamic rendering.

1. The route contains one or more dynamic segments, which means that the corresponding page uses the params prop in order to render some data that depends on the dynamic segments. Now, these dynamic segments can only be known at request time, and therefore, the route needs to become dynamic.


2. The routes page component reads some search param or also called query param from the URL. And an example of a search param could be /product?quantity=23.

3. if any of the routes' server components reads incoming headers or cookies, the route will also be switched to dynamic rendering as well.

Now, it might seem strange that this alone makes Next.js render a route dynamically but if we think about it, this actually makes sens because both the search params and headers and cookies cannot be known by Next.js at build time. They depend inherently on the incoming request, which means that the route must be rendered anew for each of these incoming requests, which is exactly what dynamic rendering does.

4. An uncached data request in any of the server components that are part of the routes component tree. This means that we can basically force Next.js to render a route dynamically simply by manipulating the way fetch requests are cached.



CDN

So a CDN (Content Delivery Network) is a network of related servers that are located at many different positions around the globe. And these servers all cache. So they store a website's static content. So things like HTML, CSS, JavaScript, and images. And then deliver this content to each user from a server located as close as possible to that user. The advantage of this is that all this data then doesn't need to travel across the entire planet from the website's host to the user because it will just come from the server that's physically closest to the user. or render.com will automatically host all your website's static assets on a global CDN like this.

SERVERLESS COMPUTING

So in the serverless computing model, we can run application code and usually backend code without managing the server ourselves. Instead, we can just run single functions on a cloud provider like AWS or Vercel or many others. And we call these functions "serverless functions". So in this model, the server is initialized and active only for the duration that the serverless function is actually running. And so this is very different from, for example, a traditional Node.js app where the server is always running and never stops. Now, this is relevant to us because as I mentioned earlier, when we deploy our website to Vercel, each dynamic route will simply become one serverless function.

So what this means is that our Next.js app is not simply one huge Node.js app that's running on a server, but instead a collection of serverless functions with the servers automatically managed by Vercel if that's where we choose to deploy the app.

For example, if one of our routes gets a huge sudden boost in traffic, Vercel will automatically provide more resources for that serverless function in order to handle all that additional load. 

Now, of course, if we only have static routes, then none of this applies. Because in that case, all of these static routes will simply be built on build time and will then be hosted on A CDN as we just learned.


EDGE

Now, this one is a bit confusing, but we can think of the edge as anything that happens as close as possible to the user. So a CDN is definitely part of an edge network because files are indeed located as close as possible to each user. However, there is also serverless edge computing, and this is simply serverless computing that does not happen on a big central server like it usually does, but instead on a network that's distributed around the globe so that the computing, or in other words, the running of the serverless function can happen as close as possible to the user. So essentially, we can think of edge computing like a CDN,
but for running code in the form of serverless functions.

Now, this is important to know because if we choose to deploy our app to Vercel, we can select certain dynamic routes to actually run on the edge so that they become even faster because again, they will run closer to the user.


INCREMENNTAL STATIC REGENERATION (ISR)

ISR is a Next.js feature that allows developers to essentially refetch and update the content of a static page in the background without the user ever noticing long after the original website has been built and deployed. This happens by re-fetching the data of a certain component or of an entire route after a certain interval that we can define in our code has passed. Now, this concept is closely related to static pages, which is why I brought it up here as well.


SSG

so now that our website is completely static, let's actually export it as a static site through a process called static site generation so that we could then very, very easily deploy it to any hosting provider that supports static sites


PPR (PARTIAL PRE-RENDERING)

the Next.js team came to the realization that most pages in a website actually don't need to be 100% static or 100% dynamic, but rather a mix between these two. So essentially partial pre-rendering is a new rendering strategy that combines the best parts of both static and dynamic rendering all in the same route. So it's a middle ground between fully static pages and fully dynamic pages. 

Now it's called pre-rendering because that's basically the same as static, and partial because the pre-rendering only happens for a part of the page. But to make sense of this, let's see how it works.

1. A pre-rendered page is served as fast as possible from a CDN, whenever a user visits the page. This makes the initial loading super fast, and leaving some holds for the dynamic content.

2. In the meantime, the server starts rendering the dynamic content, which of course takes a bit longer that just sending the static shell, but as soon as some rendering result are available, the server starts streaming the dynamic parts of the page to the client filling the holds that we had left.

As a result, we end up with even faster pages that can mostly be delivered from the edge (CDN), even when there are small dynamically rendered parts on the page. This means that pages are no longer forced to be completely dynamically rendered just because one tiny part of the page depends onn the incoming request or an uncatched data request.

How do we actually implement this in our app?

- If you want to use partial pre-rendering, you needs to be turned on in config file.

- By default, Next.js will try to statically render as much of each route as possible. And this statically rendered parts will then become the static shell. 

- However, some parts of the route might by dynamic. For example, a component that uses the cookies function. With partial pre-rendering, we can just place that dynamic component into a suspense boundary. We simply use a suspense to tell Next.js that whatever is inside the suspense is dynamic.

- And it makes sense to use a boundary in the form of suspense because it basically prevents the dynamic part, such as reading a header or making a non-cached fetch request from spreading onto the rest of the route, which would make the entire route dynamic, which we might not want. So essentially the suspense boundary isolates the dynamic components or sub trees that will be dynamically rendered.

- Now, while that dynamic part is rendering, we can provide a static fallback that will be rendered immediately by passing it to the suspense component. Then once the rendering is done, each dynamic part will simply be inserted into the static shell replacing that suspense fallback that we had specified initially.


CACHING IN THE CONTEXT OF WEB AAPLICATION

Caching essentially means taking data that has been fetched or computed and storing it in a temporary location for future access. This way, when we need the same data again in the future, we can just take it from the cache instead of re fetching or recomputing it every time the data is needed again.

In Next.js, caching is very aggressive, both on the server and the user's browser. Basically, everything that can be cached, will be cached by Next.js such as fetch data, visited routes, and so on.

Now, besides taking care of caching, Next.js also provides APIs to revalidate the different caches. And revalidating is simply to remove all data from a cache and update it with fresh data.

So the idea behind caching is that it makes apps not only more performant with faster page loads, but it also saves computing and data access costs. So imagine you have your data in some content management system and you pay each time that you access data using an API. So if caching allows you to fetch the data way less often, you might end up paying a lot less for data access. So caching can definitely be a huge advantage.

The problem is the very aggressive caching that I mentioned earlier, which means that caching is always on by default in Next.js apps, at least in the app router. This can lead to some strange and unexpected behaviors like the page displaying stale data on the client, so data that hasn't been updated. Some caches can't even be turned off, it becomes very annoying to work with this cache.

There are 4 different caching mechanisms in Next.js

- 3 of which cache store data on the server. Those are called request memoization, data cache, full route cache. Then on the client, we have the router cache.

1. Request memoization - is a technique that caches the data that has been fetched
with similar get requests during the lifespan of one request by one user. In other words, data is cached and reused only "During" exactly one page render. This way when a certain route fetches the same data in multiple places in the component tree during one render, only one actual network request will be made. So this cache is a little bit like a short term memory for fetched data.

Now, as an example, if we fetched products in five different components, Next.js would only get this data from the API once and not five times. So again, this cache allows us to fetch the same data at multiple places in the tree without making multiple network requests.

And this is actually great because this way if we need the same data in five components, we don't have to fetch it all the way at the top of the tree and then pass it down to those five components using props. We can just fetch it everywhere and not worry about multiple requests. Plus, of course, making fewer requests also makes the page faster and might even save costs.

Now, this mechanism only works with the native fetch function and when the requests are exactly the same, so with the same URL and options object. Also, this is actually a React feature, and so it only works in the React component tree, not in route handlers or server actions.


2. Data cache - stores all the data that has been fetched either in a specific route or from a single fetch request. Now, what's unique about this cache is that the data stays there basically forever unless we decide to revalidate the cache, which remember, means to clear it and re fetch the data. This means that the data is available across multiple requests from different users, and it even survives when the app is redeployed.

So if we had, for example, 1 million users requesting the same data over time, Next.js would only have made one fetch request. So every user would get the exact same data. 

And this sounds a lot like static pages, right? Where every user gets the exact same page. Well, that's because it's this data that actually feeds into static pages, or in other words, it's this data that is used to statically render routes. Now, when this data is revalidated, the corresponding static page will simply be regenerated, and this is the whole idea behind ISR or incremental static regeneration that we talked about earlier. So it's this cache mechanism and then revalidating it that makes this feature possible.

So this is actually also a great cache. It really boosts performance as it prevents so many network requests to the original data source. It's also by far the most important one to think about for us developers because it's very configurable.


3. Full route cache - stores the entire static pages in the form of HTML and RSC payload at build time. And as we already learned, static pages only have to be built once and can then be served to multiple users. So this cache is what enables static pages to work the way they do, basically acting as a storing mechanism for these static routes. So again, conceptually, the full route cache is nothing more than building static routes and storing them as HTML and RSC payload. And since this cache is so related to the data cache, the full route cache is persisted until the data cache is invalidated. Because if the underlying data changes, then the page needs to be regenerated and stored in the cache again in order to reflect the latest data. 

Now, unlike the data cache, this one does not survive redeploys. So it will be cleared when you deploy a new version of the application.

4. Router cache - this cache is used to store right in the browser, all the pre fetched pages, as well as all pages that the user visits while navigating around the application. This applies to both static and dynamic routes because the browser doesn't care about how the route was generated at all. It doesn't even know about that. Now, the idea behind this cache is that having all the pages stored in memory allows for instant or almost instant navigations, which gives the user the feel of a true single page application with no hard reloads. Now, the problem with this cache is the fact that pages are not requested from the server again, as the user navigates back and forth, which can lead to stale data being displayed.

In fact, pages are stored for 30 seconds if they are dynamic and for 5 minutes if they're a static with no way of revalidating this cache unless the user performs a hard reload or closes an reopens this tab.

---------------------------------

This is how caching works in production but not duing development. So in development, there is almost no caching happening whatsoever, so that we always see fresh data while 


How we can revalidate each cache and how we can opt out(ยกเลิก) ?

1. Request memoization

 1.1 Revalidate: there is no way of revalidating it because this concept doesn't really apply here. Memorization happens only over the lifespan of a single page render. So the data isn't even persisted anywhere, and so we can't revalidate it.

 1.2 Opt out: We can use an abort controller with the fetch function. Now, I'm not showing the whole syntax here because this is generally not needed.

2. Data cache

 2.1 Revalidate: We can set the data cache to be automatically revalidated after a certain amount of time has passed. We can do for all the data onn a certain page by exporting a revalidate const from page.js. set to a number of seconds after which the cache should be cleared and the data be refetched. Alternatively, we can revalidate only the result of a certain fetch request. Both are time-based validatio but there is also on demand revalidation where we can manually call the revalidatePath or revalidateTag function in order to revalidate the cache on a certain path or a certain tag. Now, as we learned previously, the full route cache is persisted until the data cache is revalidate. So this means that revalidating the data cache will of course also revalidate the full route cache. And again, this makes sense because the static pages depend on the cache data. And if that data is no longer fresh, then the pages need to be regenerated in the full route cache again. And remember, this is exactly the concept of incremental static regeneration.

 2.2 Opt out: Now, if we don't want to cache at all, we can opt the entire page out of the data cache simply by exporting the revalidate const like before in time-based revalidation, but this time set to zero seconds. So revalidating after zero seconds means to always revalidate, which effectively opts the page out of the data cache, it turns the cache off. We can also force the entire page to become dynamic with the dynamic constant, as we've also seen in an earlier lecture. And so this will also turn off the data cache because this cache is only for static data. So these two have basically the same effect, but I think revalidate set to zero makes a bit more sense because it's more explicit. On the other hand, we can also turn off caching for single fetch requests using this API, and also for an individual server component by calling the no store function inside of it. Now, using any of these APIs will force the entire page to become dynamic unless you are using partial pre rendering. What matters is that as the page becomes dynamic, the full route cache no longer caches it because this cache is only for static pages.


3. Router cache

 3.1 Revalidate: this one also gets revalidated by manually revalidating the data cache with revalidatePath or revalidateTag as long as it's being done in a server action, which we'll learn all about later. And once again, if we think about this, it makes sense that it works this way because if we declare the data in the cache as being old by revalidating it, then the pages that are cached in the user's browser and depend on this data should also be refreshed with the fresh data. There are, however, two more ways of revalidating the router cache, which is forcing a reload with Router.refresh or by setting or deleting a cookie in a server action. 
 
 3.2 Opt out: it's not possible to opt out of this cache. This, in my opinion, makes no sense at all, and I can't actually imagine that this will change in the future because it's indeed quite problematic. When our users use our app, they expect the data that they see to be always up-to-date, and we can simply not guarantee that because of this cache. If the data on a page is updated by something other than revalidation, so without the cache knowing about this update, we're out of luck.


 NEXTAUTH (auth with google)

 1. setting env with NEXTAUTH_URL(url of your running app) & NEXTAUTH_SECRET (Whatever you want)
 2. Configure Google in order to accept logins for out application.
  2.1 Go to Google developer console
  2.2 Create a new project
  2.3 Go to APIs & Services and then OAuth consent screen (this is kind of screen that you see when you log in using google account) and create it.
  2.4 OAuth consent screen, you will see clients tab then create OAuth 2.0. Authorized Javascript origins need to be exactly the same as NEXTAUTH_URL and Authorized redirect URLs http://localhost:3000/api/auth/callback/google
  2.5 Copy client id and client secret to env
  2.6 npm install next-auth@beta
  2.7 Just code (check out auth.js and api/auth/[...nextauth]/route.js)



MIDDLEWARE

In the case of Next.js, a middleware is a function that sits between the incoming request and the response. Or in other words, Next.js middleware allows us to run some code based on the incoming request but before the response is completed. So, the way this works is that by default, middleware runs before every single route in our Next.js app. Now, we can use a so-called matcher to specify for which routes the middleware should run. 

But the important point is that middleware always runs after the request, but before the route the user is visiting is rendered and sent back. Middleware is chunk of code is in one central place that runs before every route. This way we can keep our components clean and leave that common logic in a central place, which needs to be one, and exactly one, middleware function. This function, called middleware, needs to be exported from middleware.js. and this file needs to be in the root folder of the Next.js project.

The main function of middleware, which powers many different use cases, is reading incoming cookies and headers, as well as setting cookies and headers on the response. This enables us to implement features such as authentication and authorization, server-side analytics, redirects based on geolocation, for example, for internationalization, A/B testing, and many more.

The middleware function always needs to produce a response, which can happen in two ways.

1. The first and most common way to produce a response is  the middleware function redirects or rewrites to some route in our app, or in other words, that the middleware runs before routes are rendered.

2. Directly send a JSON response to the client. Now, we can still read and set cookies, and headers, of course, but in this case, the route won't ever be reached and rendered, so it's completely bypassed.



SERVER ACTION

- Fetching Data is not enough, the user needs a way to create new data, update data, and delete data. And therefore, Server Actions are the second missing part of the React Server Components paradigm. So Server Actions complement Server Components in order to enable us to build Full-Stack apps all within React, tightly integrated with some new React Hooks and Features.

Now, the idea behind Server Actions is really simple. They're just asynchronous functions that run exclusively on the server. They are very easily created just by adding the new Use Server Directive, either to the top of a function in a Server Component or to the top of a standalone file from which we can then export multiple Server Actions. So these are the 2 options for defining or creating Server Actions. And so let's discuss them a bit further. 

1. Server Actions can be defined right inside a Server Component, where they can then be used directly or passed as a prop to a Client Component. And remember how usually we cannot pass functions as props to Client Components. But Server Actions are actually an exception to that rule. So Server Actions can flow from the server to the client and be used there. But again, they can also just be invoked right in the Server Component in which they are created.

2. The second place in which Server Actions can be created, is in a dedicated Server Action Module, which needs to start with the Use Server Directive. Then all functions that we export from that file simply become Server Actions, which can then be imported into any Server or even Client Component. And this is actually the recommended way which we'll be using most of the time, because this way all the Mutations are stored in one central place. It can also be multiple files, but it's common to have just one, unless you have like a huge application.

Please note: "use server" is really only for server actions, not for server components. Server components are the default component and don't require any directive.

The Use Client Directive is then like a bridge that allows our code to cross from the server to the client. This is similar to including a script URL with the script tag in an HTML file that is sent to the browser. 

Now, on the other hand, the Use Server Directive is simply the other way around. So it bridges the gap from client to server, basically allowing the client to talk to the server. So in a sense, it's like an API endpoint, which allows frontend applications to do exactly that, so to talk from the client to the server.

Now speaking of API endpoints, that's actually exactly what Server Actions are. So behind the scenes, the way Server Actions work, is that Next.js will automatically create an API endpoint for each Server Action that we create. So each Server Action basically gets its own URL, which is sent to the client. So it's important to note that the function itself never reaches the client, only the URL. This means that the code itself will always stay on the server and therefore, in Server Actions, it's safe to directly connect to databases, use secret API keys and so on. Again, because it's impossible that the code is leaked to the browser.

Now whenever a Server Action is invoked, so when it's called as a result of a user interaction, behind the scenes, a POST request will be made to the endpoint and all inputs that are sent along the request will be serialized.

But as developers, we never see or use an API endpoint or a URL. It's all abstracted away in the Server Action. So all we see and use is the function itself.

Server Actions are typically used to handle form submissions, meaning that we can use the Server Action as an action attribute of a regular form element no matter if that form is placed in a Server or a Client Component. And this interaction between forms and Server Actions is one of the special things about Server Actions. They just make forms work without any additional code on the frontend. And again, it doesn't even matter if that form is a Server Component or a Client Component. It will just work like magic. So forms will simply automatically take all the form data and send it to the Server Action in a serialized form using the provided API endpoint behind the scenes. And the Server Action can then respond if we want, and we can handle that response as we'll see later.

Now, besides forms, Server Actions can also be called just like regular functions in event handlers and useEffects. This of course, only works on the client, as only Client Components are interactive. Now, in terms of what we actually do in Server Actions, as we already learned, their goal is mostly to perform data mutations. So creating, updating and deleting data, just like when we built our own API.

Now, when the underlying data of our page changes, the UI must update as a result, right? However, since that data is not stored as state on the client, we do not update the UI by updating state. Instead, what we need to do is to manually revalidate the data cache whenever we perform a data mutation. So Server Actions are tightly integrated into the Next.js caching and revalidation system. And so we can easily revalidate the cache on demand with revalidatePath and revalidateTag,

Server Actions, we can also work with cookies and really run any other code that we want here, as long as it's relevant to the action that we're performing. But no matter what we do, we always need to keep in mind that this code is effectively running on our backend, and therefore, we need to make sure that the user is authorized to perform the action, and we need to assume that inputs are unsafe. So just like we do in regular backend development.


OPTIMISTIC UI

Optimistic UI is a trick and a technique that we can use in order to improve the perceived performance of a user interface. And it's called optimistic(มองโลกในแง่ดี) because we assume that a certain asynchronous operation will be successful before it has even finished, so while it's still working in the background.

Now in this case, what we're gonna do is to remove a booking here from the UI immediately when the user clicks one of these delete buttons here. So while it is actually still being deleted in the background. So in this situation, we're being optimistic that the deletion will indeed be successful. And if it's not, then the state will simply return and the UI will come back to this current form. So the goal of this technique is to improve the user experience by a lot, because it makes the app feel so much faster and more responsive, without having all these loading spinners all over the place.

Now, React can help us implement this common pattern by using a new modern hook called useOptimistic. And so this hook allows us to show a different new state while some async action is still happening.